{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques -1 Scrape the details of most viewed videos on YouTube from Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Loading Driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\thunderbolt\\sof\\chromedriver.exe\")\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "# Giving the name of website we have to  scrap\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\"\n",
    "\n",
    "#Getting Url \n",
    "driver.get(url)\n",
    "\n",
    "rank  = []\n",
    "name = []\n",
    "artist  = []\n",
    "upload_date   = []\n",
    "views= []\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "Task1= driver.find_element_by_xpath(\"//td[@class='mbox-text']/span[@class='plainlinks']/a[1]\")\n",
    "Task1.click()\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Task2= driver.find_element_by_xpath(\"//div[@class='searchresults mw-searchresults-has-iw']//li[1]//div[@class='mw-search-result-heading']/a[1]\")\n",
    "Task2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "\n",
    "Task3=driver.find_elements_by_xpath(\"//tbody/tr/td[1]\")\n",
    "for i in Task3[0:30]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        rank.append(\"--\") \n",
    "    else:\n",
    "        rank.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task4=driver.find_elements_by_xpath(\"//tbody/tr/td[2]\")\n",
    "for i in Task4[0:30]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        name.append(\"--\") \n",
    "    else:\n",
    "        name.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task5=driver.find_elements_by_xpath(\"//tbody/tr/td[3]\")\n",
    "for i in Task5[0:30]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        artist.append(\"--\") \n",
    "    else:\n",
    "        artist.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Task6=driver.find_elements_by_xpath(\"//tbody/tr/td[4]\")\n",
    "for i in Task6[0:30]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        views.append(\"--\") \n",
    "    else:\n",
    "        views.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "\n",
    "Task7=driver.find_elements_by_xpath(\"//tbody/tr/td[5]\")\n",
    "for i in Task7[0:30]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        upload_date.append(\"--\") \n",
    "    else:\n",
    "        upload_date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upload_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),len(name),len(artist),len(upload_date),len(views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTube_Videos = pd.DataFrame({'Rank' : rank ,'Name' : name , 'Artist' :artist , 'Upload Date' : upload_date , 'Views(Billions)' : views} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Some Data Cleaning \n",
    "YouTube_Videos['Name'] = YouTube_Videos['Name'].str.replace('\\d+', '')\n",
    "YouTube_Videos['Name']= YouTube_Videos['Name'].str.replace('[', '')\n",
    "YouTube_Videos['Name']= YouTube_Videos['Name'].str.replace(']', '')\n",
    "YouTube_Videos['Name'] = YouTube_Videos['Name'].str.replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views(Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>7.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi featuring Daddy Yankee</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa featuring Charlie Puth</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson featuring Bruno Mars</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>3.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo featuring Cutty Ranks</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias featuring Descemer Bueno and ...</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer and DJ Snake featuring MØ</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry featuring Juicy J</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5 featuring Cardi B</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>2.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>J Balvin and Willy William</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Blank Space</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>November 10, 2014</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira featuring Freshlyground</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Chantaje</td>\n",
       "      <td>Shakira featuring Maluma</td>\n",
       "      <td>November 18, 2016</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                       Name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                               Shape of You   \n",
       "3    4.                              See You Again   \n",
       "4    5.   Masha and the Bear – Recipe for Disaster   \n",
       "5    6.                       Johny Johny Yes Papa   \n",
       "6    7.                                Uptown Funk   \n",
       "7    8.                              Gangnam Style   \n",
       "8    9.  Learning Colors – Colorful Eggs on a Farm   \n",
       "9   10.                                      Sorry   \n",
       "10  11.                                  Bath Song   \n",
       "11  12.                                      Sugar   \n",
       "12  13.                Phonics Song with Two Words   \n",
       "13  14.                                       Roar   \n",
       "14  15.                          Thinking Out Loud   \n",
       "15  16.                             Counting Stars   \n",
       "16  17.                               Shake It Off   \n",
       "17  18.                             Dame Tu Cosita   \n",
       "18  19.                                   Bailando   \n",
       "19  20.                                    Lean On   \n",
       "20  21.                                      Faded   \n",
       "21  22.                                 Dark Horse   \n",
       "22  23.                             Girls Like You   \n",
       "23  24.                                 Let Her Go   \n",
       "24  25.                                   Mi Gente   \n",
       "25  26.                                      Hello   \n",
       "26  27.                                Blank Space   \n",
       "27  28.           Waka Waka (This Time for Africa)   \n",
       "28  29.                                    Perfect   \n",
       "29  30.                                   Chantaje   \n",
       "\n",
       "                                               Artist        Upload Date  \\\n",
       "0                      Pinkfong Kids' Songs & Stories      June 17, 2016   \n",
       "1                   Luis Fonsi featuring Daddy Yankee   January 12, 2017   \n",
       "2                                          Ed Sheeran   January 30, 2017   \n",
       "3                  Wiz Khalifa featuring Charlie Puth      April 6, 2015   \n",
       "4                                          Get Movies   January 31, 2012   \n",
       "5                                         LooLoo Kids    October 8, 2016   \n",
       "6                    Mark Ronson featuring Bruno Mars  November 19, 2014   \n",
       "7                                                 Psy      July 15, 2012   \n",
       "8                                         Miroshka TV  February 27, 2018   \n",
       "9                                       Justin Bieber   October 22, 2015   \n",
       "10                         Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "11                                           Maroon 5   January 14, 2015   \n",
       "12                                          ChuChu TV      March 6, 2014   \n",
       "13                                         Katy Perry  September 5, 2013   \n",
       "14                                         Ed Sheeran    October 7, 2014   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                       Taylor Swift    August 18, 2014   \n",
       "17                    El Chombo featuring Cutty Ranks      April 5, 2018   \n",
       "18  Enrique Iglesias featuring Descemer Bueno and ...     April 11, 2014   \n",
       "19              Major Lazer and DJ Snake featuring MØ     March 22, 2015   \n",
       "20                                        Alan Walker   December 3, 2015   \n",
       "21                       Katy Perry featuring Juicy J  February 20, 2014   \n",
       "22                         Maroon 5 featuring Cardi B       May 31, 2018   \n",
       "23                                          Passenger      July 25, 2012   \n",
       "24                         J Balvin and Willy William      June 29, 2017   \n",
       "25                                              Adele   October 22, 2015   \n",
       "26                                       Taylor Swift  November 10, 2014   \n",
       "27                    Shakira featuring Freshlyground       June 4, 2010   \n",
       "28                                         Ed Sheeran   November 9, 2017   \n",
       "29                           Shakira featuring Maluma  November 18, 2016   \n",
       "\n",
       "   Views(Billions)  \n",
       "0             7.39  \n",
       "1             7.09  \n",
       "2             5.10  \n",
       "3             4.85  \n",
       "4             4.38  \n",
       "5             4.37  \n",
       "6             4.03  \n",
       "7             3.88  \n",
       "8             3.66  \n",
       "9             3.37  \n",
       "10            3.34  \n",
       "11            3.34  \n",
       "12            3.30  \n",
       "13            3.22  \n",
       "14            3.13  \n",
       "15            3.13  \n",
       "16            2.99  \n",
       "17            2.94  \n",
       "18            2.94  \n",
       "19            2.93  \n",
       "20            2.92  \n",
       "21            2.92  \n",
       "22            2.91  \n",
       "23            2.85  \n",
       "24            2.82  \n",
       "25            2.75  \n",
       "26            2.68  \n",
       "27            2.66  \n",
       "28            2.65  \n",
       "29            2.60  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting  Final Data\n",
    "YouTube_Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-2 Scrape the details team India’s international fixtures from bcci.tv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#Loading Driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\thunderbolt\\sof\\chromedriver.exe\")\n",
    "\n",
    "# Giving the name of website we have to  scrap\n",
    "url = \"https://www.bcci.tv/\"\n",
    "\n",
    "#Getting Url \n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "match = []\n",
    "series = []\n",
    "place = []\n",
    "date  = []\n",
    "month = []\n",
    "time  = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Task1 = driver.find_element_by_xpath(\"//li[1]//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']\")\n",
    "Task1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Task2 = driver.find_element_by_xpath(\"//li[1]/div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']/div[1]/ul[1]/li[1]/a[@href='/international/fixtures']\")\n",
    "Task2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Match , Series , Place , Date , Month and Time Data.\n",
    "\n",
    "Task3=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/strong\")\n",
    "for i in Task3:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        match.append(\"--\") \n",
    "    else:\n",
    "        match.append(i.text)\n",
    "\n",
    "Task4=driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\")\n",
    "for i in Task4:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        series.append(\"--\") \n",
    "    else:\n",
    "        series.append(i.text)\n",
    "\n",
    "\n",
    "Task5=driver.find_elements_by_xpath(\"//div[@class='fixture__full-date']/span\")\n",
    "for i in Task5:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        date.append(\"--\") \n",
    "    else:\n",
    "        date.append(i.text)\n",
    "\n",
    "\n",
    "Task6=driver.find_elements_by_xpath(\"//div[@class='fixture__date-details']/span[1]\")\n",
    "for i in Task6:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        month.append(\"--\") \n",
    "    else:\n",
    "        month.append(i.text)\n",
    "        \n",
    "\n",
    "\n",
    "Task7=driver.find_elements_by_xpath(\"//div[@class='fixture__date-details']/span[2]\")\n",
    "for i in Task7:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        time.append(\"--\") \n",
    "    else:\n",
    "        time.append(i.text)\n",
    "\n",
    "Task8=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\")\n",
    "for i in Task8:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        place.append(\"--\") \n",
    "    else:\n",
    "        place.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(match),len(series),len(place),len(date),len(month),len(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>AUSTRALIA V INDIA 2020/21</td>\n",
       "      <td>Sydney Cricket Ground, Sydney</td>\n",
       "      <td>08</td>\n",
       "      <td>DECEMBER</td>\n",
       "      <td>13:40 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>AUSTRALIA V INDIA 2020/21</td>\n",
       "      <td>Adelaide Oval, Adelaide</td>\n",
       "      <td>17</td>\n",
       "      <td>DECEMBER</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>AUSTRALIA V INDIA 2020/21</td>\n",
       "      <td>Melbourne Cricket Ground, Melbourne</td>\n",
       "      <td>26</td>\n",
       "      <td>DECEMBER</td>\n",
       "      <td>05:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>AUSTRALIA V INDIA 2020/21</td>\n",
       "      <td>Sydney Cricket Ground, Sydney</td>\n",
       "      <td>07</td>\n",
       "      <td>JANUARY</td>\n",
       "      <td>05:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>AUSTRALIA V INDIA 2020/21</td>\n",
       "      <td>Brisbane Cricket Ground, Brisbane</td>\n",
       "      <td>15</td>\n",
       "      <td>JANUARY</td>\n",
       "      <td>05:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>04</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>12</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>25</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>02</td>\n",
       "      <td>SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>10</td>\n",
       "      <td>SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                     Series                                Place  \\\n",
       "0    3rd T20I  AUSTRALIA V INDIA 2020/21        Sydney Cricket Ground, Sydney   \n",
       "1    1st Test  AUSTRALIA V INDIA 2020/21              Adelaide Oval, Adelaide   \n",
       "2    2nd Test  AUSTRALIA V INDIA 2020/21  Melbourne Cricket Ground, Melbourne   \n",
       "3    3rd Test  AUSTRALIA V INDIA 2020/21        Sydney Cricket Ground, Sydney   \n",
       "4    4th Test  AUSTRALIA V INDIA 2020/21    Brisbane Cricket Ground, Brisbane   \n",
       "5    1st Test       ENGLAND V INDIA 2021             Trent Bridge, Nottingham   \n",
       "6    2nd Test       ENGLAND V INDIA 2021                       Lord's, London   \n",
       "7    3rd Test       ENGLAND V INDIA 2021                    Headingley, Leeds   \n",
       "8    4th Test       ENGLAND V INDIA 2021                     The Oval, London   \n",
       "9    5th Test       ENGLAND V INDIA 2021             Old Trafford, Manchester   \n",
       "\n",
       "  Date      Month       Time  \n",
       "0   08   DECEMBER  13:40 IST  \n",
       "1   17   DECEMBER  09:30 IST  \n",
       "2   26   DECEMBER  05:00 IST  \n",
       "3   07    JANUARY  05:00 IST  \n",
       "4   15    JANUARY  05:30 IST  \n",
       "5   04     AUGUST  15:30 IST  \n",
       "6   12     AUGUST  15:30 IST  \n",
       "7   25     AUGUST  15:30 IST  \n",
       "8   02  SEPTEMBER  15:30 IST  \n",
       "9   10  SEPTEMBER  15:30 IST  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting  Final Data.\n",
    "\n",
    "Matches = pd.DataFrame({'Match Title' : match ,'Series' : series , 'Place' :place, 'Date' : date , 'Month': month ,'Time' : time} )\n",
    "Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-3 Scrape the details of selenium exception from guru99.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Loading Driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\thunderbolt\\sof\\chromedriver.exe\")\n",
    "\n",
    "# Giving the name of website we have to  scrap\n",
    "url = \"https://www.guru99.com/\"\n",
    "\n",
    "#Getting Url \n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(8)\n",
    "\n",
    "Exception_Name = []\n",
    "Description = []\n",
    "\n",
    "time.sleep(8)\n",
    "Task1 = driver.find_element_by_xpath(\"//ul[@class='menu']/li[3]/a[@title='Selenium']\")\n",
    "Task1.click()\n",
    "time.sleep(8)\n",
    "Task2 = driver.find_element_by_xpath(\"//td[@class='responsivetable']/a[@title='Selenium Exception Handling (Common Exceptions List)']/strong\")\n",
    "Task2.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Exception Name and Description Data.\n",
    "\n",
    "Task3=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]\")\n",
    "for i in Task3[1:42]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        Exception_Name.append(\"--\") \n",
    "    else:\n",
    "        Exception_Name.append(i.text)\n",
    "\n",
    "Task4=driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2]\")\n",
    "for i in Task4[1:42]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        Description.append(\"--\") \n",
    "    else:\n",
    "        Description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41\n"
     ]
    }
   ],
   "source": [
    "print(len(Exception_Name),len(Description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can't be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n't sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception Name  \\\n",
       "0            ElementNotVisibleException   \n",
       "1         ElementNotSelectableException   \n",
       "2                NoSuchElementException   \n",
       "3                  NoSuchFrameException   \n",
       "4               NoAlertPresentException   \n",
       "5                 NoSuchWindowException   \n",
       "6        StaleElementReferenceException   \n",
       "7              SessionNotFoundException   \n",
       "8                      TimeoutException   \n",
       "9                    WebDriverException   \n",
       "10            ConnectionClosedException   \n",
       "11     ElementClickInterceptedException   \n",
       "12      ElementNotInteractableException   \n",
       "13             ErrorInResponseException   \n",
       "14  ErrorHandler.UnknownServerException   \n",
       "15         ImeActivationFailedException   \n",
       "16             ImeNotAvailableException   \n",
       "17         InsecureCertificateException   \n",
       "18             InvalidArgumentException   \n",
       "19         InvalidCookieDomainException   \n",
       "20          InvalidCoordinatesException   \n",
       "21          InvalidElementStateExceptio   \n",
       "22            InvalidSessionIdException   \n",
       "23       InvalidSwitchToTargetException   \n",
       "24                  JavascriptException   \n",
       "25                        JsonException   \n",
       "26             NoSuchAttributeException   \n",
       "27       MoveTargetOutOfBoundsException   \n",
       "28               NoSuchContextException   \n",
       "29                NoSuchCookieException   \n",
       "30                    NotFoundException   \n",
       "31          RemoteDriverServerException   \n",
       "32                  ScreenshotException   \n",
       "33           SessionNotCreatedException   \n",
       "34           UnableToSetCookieException   \n",
       "35           UnexpectedTagNameException   \n",
       "36              UnhandledAlertException   \n",
       "37      UnexpectedAlertPresentException   \n",
       "38               UnknownMethodException   \n",
       "39          UnreachableBrowserException   \n",
       "40          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0   This type of Selenium exception occurs when an...  \n",
       "1   This Selenium exception occurs when an element...  \n",
       "2   This Exception occurs if an element could not ...  \n",
       "3   This Exception occurs if the frame target to b...  \n",
       "4   This Exception occurs when you switch to no pr...  \n",
       "5   This Exception occurs if the window target to ...  \n",
       "6   This Selenium exception occurs happens when th...  \n",
       "7   The WebDriver is acting after you quit the bro...  \n",
       "8   Thrown when there is not enough time for a com...  \n",
       "9   This Exception takes place when the WebDriver ...  \n",
       "10  This type of Exception takes place when there ...  \n",
       "11  The command may not be completed as the elemen...  \n",
       "12  This Selenium exception is thrown when any ele...  \n",
       "13  This happens while interacting with the Firefo...  \n",
       "14  Exception is used as a placeholder in case if ...  \n",
       "15  This expectation will occur when IME engine ac...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17  Navigation made the user agent to hit a certif...  \n",
       "18  It occurs when an argument does not belong to ...  \n",
       "19  This happens when you try to add a cookie unde...  \n",
       "20  This type of Exception matches an interacting ...  \n",
       "21  It occurs when command can't be finished when ...  \n",
       "22  This Exception took place when the given sessi...  \n",
       "23  This occurs when the frame or window target to...  \n",
       "24  This issue occurs while executing JavaScript g...  \n",
       "25  It occurs when you afford to get the session w...  \n",
       "26  This kind of Exception occurs when the attribu...  \n",
       "27  It takes place if the target provided to the A...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29  This Exception occurs when no cookie matching ...  \n",
       "30  This Exception is a subclass of WebDriverExcep...  \n",
       "31  This Selenium exception is thrown when the ser...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33  It happens when a new session could not be suc...  \n",
       "34  This occurs if a driver is unable to set a coo...  \n",
       "35  Happens if a support class did not get a web e...  \n",
       "36  This expectation occurs when there is an alert...  \n",
       "37  It occurs when there is the appearance of an u...  \n",
       "38  This Exception happens when the requested comm...  \n",
       "39  This Exception occurs only when the browser is...  \n",
       "40  This occurs when remote WebDriver does n't sen...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting  Final Data.\n",
    "\n",
    "Selenium = pd.DataFrame({'Exception Name' : Exception_Name, 'Description' :Description} )\n",
    "Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-4 Scrape the details of State-wise GDP of India from statisticstime.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "rank = []\n",
    "state = []\n",
    "gsdp1 = []\n",
    "gsdp2 = []\n",
    "share = []\n",
    "gdp = []\n",
    "\n",
    "#Loading Driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\thunderbolt\\sof\\chromedriver.exe\")\n",
    "\n",
    "# Giving the name of website we have to  scrap\n",
    "url = \"http://statisticstimes.com/\"\n",
    "\n",
    "#Getting Url \n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(8)\n",
    "\n",
    "time.sleep(8)\n",
    "Task1 = driver.find_element_by_xpath(\"//div[1]/div[2]/div[2]/button\")\n",
    "Task1.click()\n",
    "time.sleep(8)\n",
    "Task2 = driver.find_element_by_xpath(\"//div[1]/div[2]/div[2]/div/a[2]\")\n",
    "Task2.click()\n",
    "time.sleep(8)\n",
    "Task2 = driver.find_element_by_xpath(\"//div[@style='float:left;background-color:seashell;width:400px;height:800px;']/ul/li[1]/a[1]\")\n",
    "Task2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Rank , State , GSDP(18-19) ,GSDP(17-18) , Share(2017) and GDP($ billion) Data.\n",
    "\n",
    "Task3=driver.find_elements_by_xpath(\"//tbody//td[@class='data1']\")\n",
    "for i in Task3[0:33]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        rank.append(\"--\") \n",
    "    else:\n",
    "        rank.append(i.text)\n",
    "        \n",
    "time.sleep(5)\n",
    "\n",
    "Task4=driver.find_elements_by_xpath(\"//tbody//td[@class='name']\")\n",
    "for i in Task4[0:33]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        state.append(\"--\") \n",
    "    else:\n",
    "        state.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task5=driver.find_elements_by_xpath(\"//tbody//td[@class='data sorting_1'][1]\")\n",
    "for i in Task5[0:33]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        gsdp2.append(\"--\") \n",
    "    else:\n",
    "        gsdp2.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task6=driver.find_elements_by_xpath(\"//tbody//td[@class='data'][1]\")\n",
    "for i in Task6[0:33]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        gsdp1.append(\"--\") \n",
    "    else:\n",
    "        gsdp1.append(i.text)\n",
    "\n",
    "        \n",
    "Task7=driver.find_elements_by_xpath(\"//tbody//td[@class='data'][2]\")\n",
    "for i in Task7[0:33]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        share.append(\"--\") \n",
    "    else:\n",
    "        share.append(i.text)\n",
    "        \n",
    "time.sleep(5)        \n",
    "\n",
    "Task8=driver.find_elements_by_xpath(\"//tbody//td[@class='data'][3]\")\n",
    "for i in Task8[0:33]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        gdp.append(\"--\") \n",
    "    else:\n",
    "        gdp.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33 33 33 33\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),len(state),len(gsdp1),len(gsdp2),len(share ),len(gdp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>GSDP(17-18)</th>\n",
       "      <th>Share(2017)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,411,600</td>\n",
       "      <td>14.11%</td>\n",
       "      <td>374.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,664,159</td>\n",
       "      <td>1,461,841</td>\n",
       "      <td>8.55%</td>\n",
       "      <td>226.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,542,432</td>\n",
       "      <td>1,376,324</td>\n",
       "      <td>8.05%</td>\n",
       "      <td>213.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,535,224</td>\n",
       "      <td>1,350,257</td>\n",
       "      <td>7.90%</td>\n",
       "      <td>209.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,314,680</td>\n",
       "      <td>7.69%</td>\n",
       "      <td>203.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,177,586</td>\n",
       "      <td>999,585</td>\n",
       "      <td>5.85%</td>\n",
       "      <td>155.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>929,124</td>\n",
       "      <td>835,558</td>\n",
       "      <td>4.89%</td>\n",
       "      <td>129.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>933,402</td>\n",
       "      <td>809,547</td>\n",
       "      <td>4.74%</td>\n",
       "      <td>125.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>865,688</td>\n",
       "      <td>753,811</td>\n",
       "      <td>4.41%</td>\n",
       "      <td>116.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,327</td>\n",
       "      <td>728,242</td>\n",
       "      <td>4.26%</td>\n",
       "      <td>112.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>700,532</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>108.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>779,652</td>\n",
       "      <td>690,098</td>\n",
       "      <td>4.04%</td>\n",
       "      <td>107.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>707,126</td>\n",
       "      <td>626,054</td>\n",
       "      <td>3.66%</td>\n",
       "      <td>97.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>557,490</td>\n",
       "      <td>484,740</td>\n",
       "      <td>2.84%</td>\n",
       "      <td>75.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>521,861</td>\n",
       "      <td>479,141</td>\n",
       "      <td>2.80%</td>\n",
       "      <td>74.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>485,376</td>\n",
       "      <td>436,374</td>\n",
       "      <td>2.55%</td>\n",
       "      <td>67.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>288,494</td>\n",
       "      <td>1.69%</td>\n",
       "      <td>44.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>311,660</td>\n",
       "      <td>284,194</td>\n",
       "      <td>1.66%</td>\n",
       "      <td>44.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>307,581</td>\n",
       "      <td>276,243</td>\n",
       "      <td>1.62%</td>\n",
       "      <td>42.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>222,836</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>34.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,181</td>\n",
       "      <td>140,613</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>21.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>138,488</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>21.489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>77,172</td>\n",
       "      <td>70,493</td>\n",
       "      <td>0.41%</td>\n",
       "      <td>10.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>-</td>\n",
       "      <td>46,133</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>7.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>38,806</td>\n",
       "      <td>0.23%</td>\n",
       "      <td>6.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>36,656</td>\n",
       "      <td>32,962</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>-</td>\n",
       "      <td>30,790</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>4.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>24,281</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>3.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>23,968</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>3.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>26,786</td>\n",
       "      <td>23,495</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>3.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>22,045</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>19,457</td>\n",
       "      <td>0.11%</td>\n",
       "      <td>3.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>7,871</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>1.221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19) GSDP(17-18) Share(2017)  \\\n",
       "0     1                Maharashtra           -   2,411,600      14.11%   \n",
       "1     2                 Tamil Nadu   1,664,159   1,461,841       8.55%   \n",
       "2     3              Uttar Pradesh   1,542,432   1,376,324       8.05%   \n",
       "3     4                  Karnataka   1,535,224   1,350,257       7.90%   \n",
       "4     5                    Gujarat           -   1,314,680       7.69%   \n",
       "5     6                West Bengal   1,177,586     999,585       5.85%   \n",
       "6     7                  Rajasthan     929,124     835,558       4.89%   \n",
       "7     8             Andhra Pradesh     933,402     809,547       4.74%   \n",
       "8     9                  Telangana     865,688     753,811       4.41%   \n",
       "9    10             Madhya Pradesh     809,327     728,242       4.26%   \n",
       "10   11                     Kerala           -     700,532       4.10%   \n",
       "11   12                      Delhi     779,652     690,098       4.04%   \n",
       "12   13                    Haryana     707,126     626,054       3.66%   \n",
       "13   14                      Bihar     557,490     484,740       2.84%   \n",
       "14   15                     Punjab     521,861     479,141       2.80%   \n",
       "15   16                     Odisha     485,376     436,374       2.55%   \n",
       "16   17                      Assam           -     288,494       1.69%   \n",
       "17   18               Chhattisgarh     311,660     284,194       1.66%   \n",
       "18   19                  Jharkhand     307,581     276,243       1.62%   \n",
       "19   20                Uttarakhand     245,895     222,836       1.30%   \n",
       "20   21           Himachal Pradesh     153,181     140,613       0.82%   \n",
       "21   22            Jammu & Kashmir           -     138,488       0.81%   \n",
       "22   23                        Goa      77,172      70,493       0.41%   \n",
       "23   24                    Tripura           -      46,133       0.27%   \n",
       "24   25                 Chandigarh           -      38,806       0.23%   \n",
       "25   26                 Puducherry      36,656      32,962       0.19%   \n",
       "26   27                  Meghalaya           -      30,790       0.18%   \n",
       "27   28                   Nagaland           -      24,281       0.14%   \n",
       "28   29                    Manipur           -      23,968       0.14%   \n",
       "29   30                     Sikkim      26,786      23,495       0.14%   \n",
       "30   31          Arunachal Pradesh           -      22,045       0.13%   \n",
       "31   32                    Mizoram           -      19,457       0.11%   \n",
       "32   33  Andaman & Nicobar Islands           -       7,871       0.05%   \n",
       "\n",
       "   GDP($ billion)  \n",
       "0         374.196  \n",
       "1         226.827  \n",
       "2         213.558  \n",
       "3         209.513  \n",
       "4         203.993  \n",
       "5         155.101  \n",
       "6         129.650  \n",
       "7         125.614  \n",
       "8         116.965  \n",
       "9         112.998  \n",
       "10        108.698  \n",
       "11        107.079  \n",
       "12         97.142  \n",
       "13         75.215  \n",
       "14         74.346  \n",
       "15         67.710  \n",
       "16         44.764  \n",
       "17         44.097  \n",
       "18         42.863  \n",
       "19         34.576  \n",
       "20         21.818  \n",
       "21         21.489  \n",
       "22         10.938  \n",
       "23          7.158  \n",
       "24          6.021  \n",
       "25          5.115  \n",
       "26          4.778  \n",
       "27          3.768  \n",
       "28          3.719  \n",
       "29          3.646  \n",
       "30          3.421  \n",
       "31          3.019  \n",
       "32          1.221  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting  Final Data\n",
    "Statics = pd.DataFrame({'Rank' : rank ,'State' : state , 'GSDP(18-19)' : gsdp1 , 'GSDP(17-18)' : gsdp2 , 'Share(2017)' : share ,'GDP($ billion)':gdp} )\n",
    "Statics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques- 5  Scrape the details of trending repositories on Github.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\thunderbolt\\sof\\chromedriver.exe\")\n",
    "\n",
    "Title=[]\n",
    "Description=[]\n",
    "Contributors=[]\n",
    "Language=[]\n",
    "\n",
    "driver.get('https://github.com/')\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "insert=driver.find_element_by_xpath(\"//li[4]/details/summary[@class='HeaderMenu-summary HeaderMenu-link px-0 py-3 border-0 no-wrap d-block d-lg-inline-block']\").click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "insert1=driver.find_element_by_xpath(\"//ul[@class='list-style-none mb-3']/li[3]/a\").click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "lan78=driver.find_elements_by_xpath(\"//article[@class='Box-row']/h1\")\n",
    "for wp in lan78:\n",
    "    wm = wp.text\n",
    "    Title.append(wm)\n",
    "    \n",
    "time.sleep(10)\n",
    "\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//article[@class='Box-row']/h1/a\")]\n",
    "for url in urls:\n",
    "    time.sleep(5)\n",
    "\n",
    "           \n",
    "        \n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        language=driver.find_element_by_xpath(\"//ul[@class='list-style-none']/li[1]/a[1]//span[1]\").text\n",
    "        \n",
    "        Language.append(language)\n",
    "    except NoSuchElementException :\n",
    "        Language.append(\" \")\n",
    "        \n",
    "    \n",
    "        \n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        contributors=driver.find_element_by_xpath(\"//div[@class='BorderGrid BorderGrid--spacious']/div[4]/div/h2[@class='h4 mb-3']//span\").text\n",
    "        \n",
    "        Contributors.append(contributors)\n",
    "    except NoSuchElementException :\n",
    "        Contributors.append(\" \")\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        cont67=driver.find_element_by_xpath(\"//div[@class='BorderGrid-row hide-sm hide-md']/div/p[@class='f4 mt-3']\").text\n",
    "       \n",
    "        Description.append(cont67)\n",
    "    except NoSuchElementException :\n",
    "        Description.append(\" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Description) ,len(Contributors) ,len(Language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WerWolv / ImHex</td>\n",
       "      <td>A Hex Editor for Reverse Engineers, Programmer...</td>\n",
       "      <td>5</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nickmccullum / algorithmic-trading-python</td>\n",
       "      <td>The repository for freeCodeCamp's YouTube cour...</td>\n",
       "      <td></td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alacritty / alacritty</td>\n",
       "      <td>A cross-platform, GPU-accelerated terminal emu...</td>\n",
       "      <td></td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bytefury / crater</td>\n",
       "      <td>Free &amp; Open Source Invoice App for Freelancers...</td>\n",
       "      <td></td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jwasham / coding-interview-university</td>\n",
       "      <td>A complete computer science study plan to beco...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acidanthera / OpenCorePkg</td>\n",
       "      <td>OpenCore bootloader</td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>github / docs</td>\n",
       "      <td>The open-source repo for docs.github.com</td>\n",
       "      <td></td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3b1b / manim</td>\n",
       "      <td>Animation engine for explanatory math videos</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rclone / rclone</td>\n",
       "      <td>\"rsync for cloud storage\" - Google Drive, Amaz...</td>\n",
       "      <td></td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rapid7 / metasploit-framework</td>\n",
       "      <td>Metasploit Framework</td>\n",
       "      <td>6</td>\n",
       "      <td>Ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CSSEGISandData / COVID-19</td>\n",
       "      <td>Novel Coronavirus (COVID-19) Cases, provided b...</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ottomated / CrewLink-server</td>\n",
       "      <td>Voice Relay server for CrewLink.</td>\n",
       "      <td>3</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>public-apis / public-apis</td>\n",
       "      <td>A collective list of free APIs for use in soft...</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SebLague / Digital-Logic-Sim</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>swisskyrepo / PayloadsAllTheThings</td>\n",
       "      <td>A list of useful payloads and bypass for Web A...</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>thedaviddias / Front-End-Checklist</td>\n",
       "      <td>🗂 The perfect Front-End Checklist for modern w...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AkihiroSuda / nerdctl</td>\n",
       "      <td>Docker-compatible CLI for containerd</td>\n",
       "      <td></td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>microsoft / restler-fuzzer</td>\n",
       "      <td>RESTler is the first stateful REST API fuzzing...</td>\n",
       "      <td>6</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>home-assistant / core</td>\n",
       "      <td>🏡 Open source home automation that puts local ...</td>\n",
       "      <td>224</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ottomated / CrewLink</td>\n",
       "      <td>Free, open, Among Us Proximity Chat</td>\n",
       "      <td>7</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aseprite / aseprite</td>\n",
       "      <td>Animated sprite editor &amp; pixel art tool (Windo...</td>\n",
       "      <td></td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>neovim / neovim</td>\n",
       "      <td>Vim-fork focused on extensibility and usability</td>\n",
       "      <td></td>\n",
       "      <td>Vim script</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GuitarML / GuitarLSTM</td>\n",
       "      <td>Deep learning models for guitar amp/pedal emul...</td>\n",
       "      <td></td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>discordjs / discord.js</td>\n",
       "      <td>A powerful JavaScript library for interacting ...</td>\n",
       "      <td></td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rabbitstack / fibratus</td>\n",
       "      <td>A modern tool for the Windows kernel explorati...</td>\n",
       "      <td></td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Repository Title  \\\n",
       "0                             WerWolv / ImHex   \n",
       "1   nickmccullum / algorithmic-trading-python   \n",
       "2                       alacritty / alacritty   \n",
       "3                           bytefury / crater   \n",
       "4       jwasham / coding-interview-university   \n",
       "5                   acidanthera / OpenCorePkg   \n",
       "6                               github / docs   \n",
       "7                                3b1b / manim   \n",
       "8                             rclone / rclone   \n",
       "9               rapid7 / metasploit-framework   \n",
       "10                  CSSEGISandData / COVID-19   \n",
       "11                ottomated / CrewLink-server   \n",
       "12                  public-apis / public-apis   \n",
       "13               SebLague / Digital-Logic-Sim   \n",
       "14         swisskyrepo / PayloadsAllTheThings   \n",
       "15         thedaviddias / Front-End-Checklist   \n",
       "16                      AkihiroSuda / nerdctl   \n",
       "17                 microsoft / restler-fuzzer   \n",
       "18                      home-assistant / core   \n",
       "19                       ottomated / CrewLink   \n",
       "20                        aseprite / aseprite   \n",
       "21                            neovim / neovim   \n",
       "22                      GuitarML / GuitarLSTM   \n",
       "23                     discordjs / discord.js   \n",
       "24                     rabbitstack / fibratus   \n",
       "\n",
       "                               Repository Description Contributors Count  \\\n",
       "0   A Hex Editor for Reverse Engineers, Programmer...                  5   \n",
       "1   The repository for freeCodeCamp's YouTube cour...                      \n",
       "2   A cross-platform, GPU-accelerated terminal emu...                      \n",
       "3   Free & Open Source Invoice App for Freelancers...                      \n",
       "4   A complete computer science study plan to beco...                      \n",
       "5                                 OpenCore bootloader                      \n",
       "6            The open-source repo for docs.github.com                      \n",
       "7        Animation engine for explanatory math videos                      \n",
       "8   \"rsync for cloud storage\" - Google Drive, Amaz...                      \n",
       "9                                Metasploit Framework                  6   \n",
       "10  Novel Coronavirus (COVID-19) Cases, provided b...                  8   \n",
       "11                   Voice Relay server for CrewLink.                  3   \n",
       "12  A collective list of free APIs for use in soft...                      \n",
       "13                                                                         \n",
       "14  A list of useful payloads and bypass for Web A...                      \n",
       "15  🗂 The perfect Front-End Checklist for modern w...                      \n",
       "16               Docker-compatible CLI for containerd                      \n",
       "17  RESTler is the first stateful REST API fuzzing...                  6   \n",
       "18  🏡 Open source home automation that puts local ...                224   \n",
       "19                Free, open, Among Us Proximity Chat                  7   \n",
       "20  Animated sprite editor & pixel art tool (Windo...                      \n",
       "21    Vim-fork focused on extensibility and usability                      \n",
       "22  Deep learning models for guitar amp/pedal emul...                      \n",
       "23  A powerful JavaScript library for interacting ...                      \n",
       "24  A modern tool for the Windows kernel explorati...                      \n",
       "\n",
       "       Language Used  \n",
       "0                C++  \n",
       "1   Jupyter Notebook  \n",
       "2               Rust  \n",
       "3                PHP  \n",
       "4                     \n",
       "5                  C  \n",
       "6         JavaScript  \n",
       "7             Python  \n",
       "8                 Go  \n",
       "9               Ruby  \n",
       "10                    \n",
       "11        TypeScript  \n",
       "12            Python  \n",
       "13                C#  \n",
       "14            Python  \n",
       "15                    \n",
       "16                Go  \n",
       "17            Python  \n",
       "18            Python  \n",
       "19        TypeScript  \n",
       "20               C++  \n",
       "21        Vim script  \n",
       "22            Python  \n",
       "23        JavaScript  \n",
       "24                Go  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting  Final Data. \n",
    "Github = pd.DataFrame({'Repository Title' : Title  , 'Repository Description' : Description  , 'Contributors Count' : Contributors , 'Language Used'  : Language}  )\n",
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques-6 - Scrape the details of top 100 songs on billiboard.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url = https://www.billiboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "\n",
    "#Loading Driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\thunderbolt\\sof\\chromedriver.exe\")\n",
    "\n",
    "# Giving the name of website we have to  scrap\n",
    "url = \"https://www.billboard.com/\"\n",
    "\n",
    "#Getting Url \n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "song_name = []\n",
    "artist_name  = []\n",
    "last_week_rank  = []\n",
    "peak_rank  = []\n",
    "weeks_on_board = []\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "Task1 = driver.find_element_by_xpath(\"//header[@class='header header--desktop padding-x--sm flex--space-between-center bg--dark']/div[@class='header__main-menu__wrapper flex--grow']/ul/li[1]/a\")\n",
    "Task1.click()\n",
    "\n",
    "time.sleep(10)\n",
    "Task2 = driver.find_element_by_xpath(\"//div[@class='charts-landing__info charts-landing__info--hot-100']/div\")\n",
    "Task2.click()\n",
    "\n",
    "time.sleep(4)\n",
    "Task3=driver.find_elements_by_xpath(\"//span[@class='chart-element__information']/span[1]\")\n",
    "for i in Task3[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        song_name.append(\"--\") \n",
    "    else:\n",
    "        song_name.append(i.text)\n",
    "        \n",
    "time.sleep(5)\n",
    "\n",
    "Task4=driver.find_elements_by_xpath(\"//span[@class='chart-element__information']/span[2]\")\n",
    "for i in Task4[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        artist_name.append(\"--\") \n",
    "    else:\n",
    "        artist_name.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task5=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in Task5[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        last_week_rank.append(\"--\") \n",
    "    else:\n",
    "        last_week_rank.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task6=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in Task6[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        peak_rank.append(\"--\") \n",
    "    else:\n",
    "        peak_rank.append(i.text)\n",
    "\n",
    "        \n",
    "Task7=driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in Task7[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        weeks_on_board.append(\"--\") \n",
    "    else:\n",
    "        weeks_on_board.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks On Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Life Goes On</td>\n",
       "      <td>BTS</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mood</td>\n",
       "      <td>24kGoldn Featuring iann dior</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dynamite</td>\n",
       "      <td>BTS</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positions</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I Hope</td>\n",
       "      <td>Gabby Barrett Featuring Charlie Puth</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Popstar</td>\n",
       "      <td>DJ Khaled Featuring Drake</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Bichota</td>\n",
       "      <td>Karol G</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Happy Does</td>\n",
       "      <td>Kenny Chesney</td>\n",
       "      <td>90</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Cover Me Up</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>So Done</td>\n",
       "      <td>The Kid LAROI</td>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Song Name                           Artist Name Last Week Rank  \\\n",
       "0   Life Goes On                                   BTS              -   \n",
       "1           Mood          24kGoldn Featuring iann dior              1   \n",
       "2       Dynamite                                   BTS             14   \n",
       "3      Positions                         Ariana Grande              3   \n",
       "4         I Hope  Gabby Barrett Featuring Charlie Puth              4   \n",
       "..           ...                                   ...            ...   \n",
       "95       Popstar             DJ Khaled Featuring Drake             83   \n",
       "96       Bichota                               Karol G              -   \n",
       "97    Happy Does                         Kenny Chesney             90   \n",
       "98   Cover Me Up                         Morgan Wallen              -   \n",
       "99       So Done                         The Kid LAROI             75   \n",
       "\n",
       "   Peak Rank Weeks On Board  \n",
       "0          1              1  \n",
       "1          1             16  \n",
       "2          1             14  \n",
       "3          1              5  \n",
       "4          3             48  \n",
       "..       ...            ...  \n",
       "95         3             19  \n",
       "96        97              1  \n",
       "97        85              6  \n",
       "98        99              1  \n",
       "99        59              5  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting  Final  Data \n",
    "billiboard = pd.DataFrame({'Song Name':song_name ,'Artist Name' :artist_name , 'Last Week Rank':last_week_rank ,'Peak Rank' : peak_rank , 'Weeks On Board' : weeks_on_board  })\n",
    "billiboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques -7 Scrape the details of Data science recruiters from naukri.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "\n",
    "#Loading Driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\thunderbolt\\sof\\chromedriver.exe\")\n",
    "\n",
    "# Giving the name of website we have to  scrap\n",
    "url = \"https://www.naukri.com/\"\n",
    "\n",
    "#Getting Url \n",
    "driver.get(url)\n",
    "\n",
    "name  = []\n",
    "designation  = []\n",
    "company  = []\n",
    "skills   = []\n",
    "location = []\n",
    "\n",
    "time.sleep(5)\n",
    "driver.switch_to_window(driver.window_handles[1])\n",
    "driver.close()\n",
    "time.sleep(5)\n",
    "driver.switch_to_window(driver.window_handles[1])\n",
    "driver.close()\n",
    "time.sleep(5)\n",
    "driver.switch_to_window(driver.window_handles[0])\n",
    "time.sleep(10)\n",
    "\n",
    "Task1 = driver.find_element_by_xpath(\"//div[@class='privacyPolicy']/div//button\")\n",
    "Task1.click()\n",
    "time.sleep(10)\n",
    "\n",
    "Task2 = driver.find_element_by_xpath(\"//div[@class='userPrompt animate']//span[1]\")\n",
    "Task2.click()\n",
    "time.sleep(10)\n",
    "\n",
    "Task3 = driver.find_element_by_xpath(\"//ul[@class='midSec menu']/li[2]/a/div\")\n",
    "Task3.click()\n",
    "\n",
    "time.sleep(5)\n",
    "driver.switch_to_window(driver.window_handles[1])\n",
    "time.sleep(5)\n",
    "\n",
    "Task4 = driver.find_element_by_xpath(\"//div[@class='sWrap lftBrd']/div[2]/input\")\n",
    "Task4.send_keys('Data Science')\n",
    "time.sleep(10)\n",
    "\n",
    "Task5 = driver.find_element_by_xpath(\"//button[@class='fl qsbSrch blueBtn']\")\n",
    "Task5.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting  Name , Designation , Company, skills and location data.\n",
    "\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//div[@class='vcard']/p/a[1]\")]\n",
    "for url in urls[0:50]:\n",
    "    time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        language=driver.find_element_by_xpath(\"//div[@class='rFrame fl infoWrapper']/div[5]/a[1]\").text\n",
    "        \n",
    "        location.append(language)\n",
    "    except NoSuchElementException :\n",
    "        location.append(\" \")\n",
    "        \n",
    "    \n",
    "        \n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        contributors=driver.find_element_by_xpath(\"//div[@class='mt10 oh']/h1\").text\n",
    "        \n",
    "        name.append(contributors)\n",
    "    except NoSuchElementException :\n",
    "        name.append(\" \")\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        cont67=driver.find_element_by_xpath(\"//div[@class='rFrame fl infoWrapper']//div[@class='ellipsis']\").text\n",
    "       \n",
    "        designation.append(cont67)\n",
    "    except NoSuchElementException :\n",
    "        designation.append(\" \")\n",
    "\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        cont67=driver.find_element_by_xpath(\"//div[@class='rFrame fl infoWrapper']/div[4]/a[1]\").text\n",
    "       \n",
    "        company.append(cont67)\n",
    "    except NoSuchElementException :\n",
    "        company.append(\" \")\n",
    "\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        cont67=driver.find_element_by_xpath(\"//div[@class='fl lPortn']/p[1]\").text\n",
    "       \n",
    "        skills.append(cont67)\n",
    "    except NoSuchElementException :\n",
    "        skills.append(\" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50 50 50\n"
     ]
    }
   ],
   "source": [
    "print (len(name),len(designation),len(company),len(skills) , len(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer , Internet Marketing Pro...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net , Java , Data Science , Linux Administrat...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Talent Acquisition Executive</td>\n",
       "      <td>Recruitment Professional</td>\n",
       "      <td>XenonStack</td>\n",
       "      <td>Web Designing , html5 , Angular.js , seo , had...</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>, Mean Stack , javascript , angularjs , mongod...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td></td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop , Spark , Digital Strategy , Data Archi...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jitendra Singh</td>\n",
       "      <td>Manager- Talent Acquisition</td>\n",
       "      <td>Compunnel Technology India Pvt. Ltd</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and APAC</td>\n",
       "      <td>Recruitment - Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Analytics , Business Intelligence , Business A...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Institute for Financial Management and Research</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Analytics &amp; Business Intelligence</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Machine Learning , algorithms , Go Getter , Co...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td></td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Qa , Ui , ux , Java Developer , Java Architect...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td></td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td></td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Mid Level</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Big Data , Hadoop , Data Analytics , Data Science</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>IT-Software/Software Services</td>\n",
       "      <td>Cochin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rakhi</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>Walkingtext Private Limited</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Mid Level, Top Mangement Level</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Data Analytics , Data Science , Machine Learni...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pooja Seth</td>\n",
       "      <td>IT Technical Recruiter</td>\n",
       "      <td>RAPS iTech</td>\n",
       "      <td>Junior Level, High Level</td>\n",
       "      <td>Chandigarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>High Level, Mid Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager - Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Java , Net , Angularjs , Hr , Infrastructure ,...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private Limited</td>\n",
       "      <td>High Level, Top Mangement Level</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Srikanth Bellup</td>\n",
       "      <td>Director</td>\n",
       "      <td>TeachR Robotics Pvt. Ltd</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Data Science , Hadoop , Rpas , Devops , Python...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Signal Processing , Machine Learning , Neural ...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>R.S Consultancy &amp; Services</td>\n",
       "      <td>Web Technologies , Project Management , Softwa...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Data Analytics , Managed Services , Team Leading</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Prateek Kumar</td>\n",
       "      <td>Head</td>\n",
       "      <td>Trisect</td>\n",
       "      <td>Junior Level</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td></td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td></td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp; Consulting Co. India</td>\n",
       "      <td></td>\n",
       "      <td>Aligarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Junior Level, High Level</td>\n",
       "      <td>Salt Lake City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Python , Php , Qa Automation , Ui , Wordpre</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td></td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head-Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td></td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Top Mangement Level, Junior Level</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Data Science , Node.js , Angularjs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director, Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td></td>\n",
       "      <td>MYSORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co-Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td></td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>java , hadoop , r , Machine Learning , spark ,...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Shailja Mishra</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Certybox Pvt.Ltd.</td>\n",
       "      <td></td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "0                                        Aakash Harit   \n",
       "1                                shravan Kumar Gaddam   \n",
       "2                        Talent Acquisition Executive   \n",
       "3                                        Anik Agrawal   \n",
       "4                            MARSIAN Technologies LLP   \n",
       "5                                        subhas patel   \n",
       "6                                      Jitendra Singh   \n",
       "7   Abhishek - Only Analytics Hiring - India and APAC   \n",
       "8     Institute for Financial Management and Research   \n",
       "9                                         Balu Ramesh   \n",
       "10                                      Asif Lucknowi   \n",
       "11                                    InstaFinancials   \n",
       "12                                    Kalpana Dumpala   \n",
       "13                                            Mubarak   \n",
       "14                                     Kushal Rastogi   \n",
       "15                                      Manisha Yadav   \n",
       "16                                       Kapil Devang   \n",
       "17                                        Riya Rajesh   \n",
       "18                                              Rakhi   \n",
       "19                                 Mahesh Babu Channa   \n",
       "20                               Rashmi Bhattacharjee   \n",
       "21                                      Faizan Kareem   \n",
       "22                                     Rithika dadwal   \n",
       "23                                      Azahar Shaikh   \n",
       "24                                         Pooja Seth   \n",
       "25                                 Sandhya Khandagale   \n",
       "26                                          Shaun Rao   \n",
       "27                                              Manas   \n",
       "28                                    Srikanth Bellup   \n",
       "29                                              kumar   \n",
       "30                                       Sunil Vedula   \n",
       "31                                        Rajat Kumar   \n",
       "32                                          Jayanth N   \n",
       "33                                      Prateek Kumar   \n",
       "34                                           SREEDHAR   \n",
       "35                                        Amit Sharma   \n",
       "36                                              Kanan   \n",
       "37                               Shashikant Chaudhary   \n",
       "38                                               Brad   \n",
       "39                                       Rutuja Pawar   \n",
       "40                                Madhusudhan Sridhar   \n",
       "41                                        Ankit Sinha   \n",
       "42                                     Gaurav Chouhan   \n",
       "43                                       Rashi Kacker   \n",
       "44                                            Ashwini   \n",
       "45                                       Balaji Kolli   \n",
       "46                                     Rajani Nagaraj   \n",
       "47                                        ROHIT Kumar   \n",
       "48                                     Amir Chowdhury   \n",
       "49                                     Shailja Mishra   \n",
       "\n",
       "                      Designation  \\\n",
       "0                      HR Manager   \n",
       "1               Company Recruiter   \n",
       "2        Recruitment Professional   \n",
       "3               Company Recruiter   \n",
       "4                                   \n",
       "5                   Founder & CEO   \n",
       "6     Manager- Talent Acquisition   \n",
       "7   Recruitment - Lead Consultant   \n",
       "8               Programme Manager   \n",
       "9                HR Administrator   \n",
       "10                       Director   \n",
       "11                 Human Resource   \n",
       "12               Executive Hiring   \n",
       "13                     Company HR   \n",
       "14                     Company HR   \n",
       "15                   HR Executive   \n",
       "16                     HR Manager   \n",
       "17     Manager Talent Acquisition   \n",
       "18         Recruitment Consultant   \n",
       "19                   HR Team Lead   \n",
       "20                        HR Head   \n",
       "21                     HR MANAGER   \n",
       "22                   HR Recruiter   \n",
       "23              Company Recruiter   \n",
       "24         IT Technical Recruiter   \n",
       "25                   HR Recruiter   \n",
       "26      Manager - Human Resources   \n",
       "27        Lead Talent acquisition   \n",
       "28                       Director   \n",
       "29                     Proprietor   \n",
       "30                            CEO   \n",
       "31                  Founder & CEO   \n",
       "32                Project Manager   \n",
       "33                           Head   \n",
       "34         Recruitment Consultant   \n",
       "35                     Consultant   \n",
       "36   senior technology instructor   \n",
       "37       HR Recruiter/HR Excutive   \n",
       "38  Manager, Technical Recruiting   \n",
       "39            Technical Recruiter   \n",
       "40                Erp Implementer   \n",
       "41                 Head-Analytics   \n",
       "42        Chief Technical Officer   \n",
       "43             Sr Product Manager   \n",
       "44      Director, Global Delivery   \n",
       "45                     Co-Founder   \n",
       "46                     HR Manager   \n",
       "47                      Architect   \n",
       "48               Managing Partner   \n",
       "49                     HR Manager   \n",
       "\n",
       "                                         Company Name  \\\n",
       "0                                Data Science Network   \n",
       "1                       Shore Infotech India Pvt. Ltd   \n",
       "2                                          XenonStack   \n",
       "3               Enerlytics Software Solutions Pvt Ltd   \n",
       "4                            MARSIAN Technologies LLP   \n",
       "5                                     LibraryXProject   \n",
       "6                 Compunnel Technology India Pvt. Ltd   \n",
       "7          Apidel Technologies Division of Transpower   \n",
       "8                                                IFMR   \n",
       "9                         Techvantage Systems Pvt Ltd   \n",
       "10                         Weupskill- Live Wire India   \n",
       "11                   CBL Data Science Private Limited   \n",
       "12                                 Innominds Software   \n",
       "13                                           MoneyTap   \n",
       "14                 QuantMagnum Technologies Pvt. Ltd.   \n",
       "15                                           Easi Tax   \n",
       "16                                     BISP Solutions   \n",
       "17                        Novelworx Digital Solutions   \n",
       "18                        Walkingtext Private Limited   \n",
       "19                                  SocialPrachar.com   \n",
       "20       AXESTRACK SOFTWARE SOLUTIONS PRIVATE LIMITED   \n",
       "21                      FirstTech Consaltants Pvt.Ltd   \n",
       "22                                   Affine Analytics   \n",
       "23                    NEAL ANALYTICS SERVICES PVT LTD   \n",
       "24                                         RAPS iTech   \n",
       "25                    Compumatrice Multimedia Pvt Ltd   \n",
       "26                                 Exela Technologies   \n",
       "27    Autumn Leaf Consulting Services Private Limited   \n",
       "28                           TeachR Robotics Pvt. Ltd   \n",
       "29                                            trainin   \n",
       "30                               Nanoprecise Sci Corp   \n",
       "31                         R.S Consultancy & Services   \n",
       "32           Dollarbird Information Services Pvt, Ltd   \n",
       "33                                            Trisect   \n",
       "34        JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "35                                    ASCO consulting   \n",
       "36                                            NY INST   \n",
       "37  3D India Staffing Research & Consulting Co. India   \n",
       "38                                        O.C. Tanner   \n",
       "39                                      Demand Matrix   \n",
       "40                                MADHUSUDHAN SRIDHAR   \n",
       "41                                     Suntech Global   \n",
       "42                           Strategic Consulting Lab   \n",
       "43                               Impel Labs Pvt. Ltd.   \n",
       "44                                       MRP Advisers   \n",
       "45                      Saras Solutions India Pvt Ltd   \n",
       "46                                        WildJasmine   \n",
       "47                                LNT Private Limited   \n",
       "48                                        Granular.ai   \n",
       "49                                  Certybox Pvt.Ltd.   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   Classic ASP Developer , Internet Marketing Pro...   \n",
       "1   .Net , Java , Data Science , Linux Administrat...   \n",
       "2   Web Designing , html5 , Angular.js , seo , had...   \n",
       "3   , Mean Stack , javascript , angularjs , mongod...   \n",
       "4                             Mid Level, Junior Level   \n",
       "5   Hadoop , Spark , Digital Strategy , Data Archi...   \n",
       "6                               Mid Level, High Level   \n",
       "7   Analytics , Business Intelligence , Business A...   \n",
       "8                   Analytics & Business Intelligence   \n",
       "9   Machine Learning , algorithms , Go Getter , Co...   \n",
       "10                                                      \n",
       "11                            Junior Level, Mid Level   \n",
       "12  Qa , Ui , ux , Java Developer , Java Architect...   \n",
       "13                                                      \n",
       "14                                                      \n",
       "15                                          Mid Level   \n",
       "16  Big Data , Hadoop , Data Analytics , Data Science   \n",
       "17                      IT-Software/Software Services   \n",
       "18                              Mid Level, High Level   \n",
       "19                            Junior Level, Mid Level   \n",
       "20                     Mid Level, Top Mangement Level   \n",
       "21  Data Analytics , Data Science , Machine Learni...   \n",
       "22                            Junior Level, Mid Level   \n",
       "23                              Mid Level, High Level   \n",
       "24                           Junior Level, High Level   \n",
       "25                              High Level, Mid Level   \n",
       "26  Java , Net , Angularjs , Hr , Infrastructure ,...   \n",
       "27                    High Level, Top Mangement Level   \n",
       "28                            Mid Level, Junior Level   \n",
       "29  Data Science , Hadoop , Rpas , Devops , Python...   \n",
       "30  Signal Processing , Machine Learning , Neural ...   \n",
       "31  Web Technologies , Project Management , Softwa...   \n",
       "32   Data Analytics , Managed Services , Team Leading   \n",
       "33                                       Junior Level   \n",
       "34                                                      \n",
       "35                                                      \n",
       "36                            Mid Level, Junior Level   \n",
       "37                                                      \n",
       "38                           Junior Level, High Level   \n",
       "39        Python , Php , Qa Automation , Ui , Wordpre   \n",
       "40                                                      \n",
       "41                                                      \n",
       "42                  Top Mangement Level, Junior Level   \n",
       "43                 Data Science , Node.js , Angularjs   \n",
       "44                                                      \n",
       "45                                                      \n",
       "46  java , hadoop , r , Machine Learning , spark ,...   \n",
       "47                              Mid Level, High Level   \n",
       "48                                                      \n",
       "49                                                      \n",
       "\n",
       "                    Location  \n",
       "0                      Delhi  \n",
       "1   Hyderabad / Secunderabad  \n",
       "2                 Chandigarh  \n",
       "3                  Ahmedabad  \n",
       "4                       Pune  \n",
       "5              UK - (london)  \n",
       "6                      Delhi  \n",
       "7          Vadodara / Baroda  \n",
       "8                    Chennai  \n",
       "9                 Trivandrum  \n",
       "10                    Indore  \n",
       "11     Bengaluru / Bangalore  \n",
       "12  Hyderabad / Secunderabad  \n",
       "13     Bengaluru / Bangalore  \n",
       "14                    Mumbai  \n",
       "15               Navi Mumbai  \n",
       "16                    Bhopal  \n",
       "17                    Cochin  \n",
       "18     Bengaluru / Bangalore  \n",
       "19  Hyderabad / Secunderabad  \n",
       "20                     Delhi  \n",
       "21  Hyderabad / Secunderabad  \n",
       "22                      Pune  \n",
       "23                      Pune  \n",
       "24                Chandigarh  \n",
       "25                      Pune  \n",
       "26                      Pune  \n",
       "27     Bengaluru / Bangalore  \n",
       "28  Hyderabad / Secunderabad  \n",
       "29     Bengaluru / Bangalore  \n",
       "30                    Others  \n",
       "31                     Delhi  \n",
       "32           Mysoru / Mysore  \n",
       "33                     Noida  \n",
       "34  Hyderabad / Secunderabad  \n",
       "35                 New Delhi  \n",
       "36                   Chennai  \n",
       "37                   Aligarh  \n",
       "38            Salt Lake City  \n",
       "39                      Pune  \n",
       "40     Bengaluru / Bangalore  \n",
       "41                    Mumbai  \n",
       "42                    Indore  \n",
       "43     Bengaluru / Bangalore  \n",
       "44                    MYSORE  \n",
       "45  Hyderabad / Secunderabad  \n",
       "46     Bengaluru / Bangalore  \n",
       "47                    Mumbai  \n",
       "48                            \n",
       "49                     Noida  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating  recruiter data. \n",
    "Recruitor = pd.DataFrame({'Name' : name  , 'Designation' : designation  , 'Company Name' : company , 'Skills'  : skills , 'Location' : location  }  )\n",
    "Recruitor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques -8 Scrape the details of Highest selling novels.\n",
    "      Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "\n",
    "#Loading Driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\thunderbolt\\sof\\chromedriver.exe\")\n",
    "\n",
    "# Giving the name of website we have to  scrap\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\"\n",
    "\n",
    "#Getting Url \n",
    "driver.get(url)\n",
    "\n",
    "book_name = []\n",
    "author_name  = []\n",
    "volumes_sold  = []\n",
    "publisher  = []\n",
    "genre  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting  Book Name , Author Name  , Volume Sold , Publisher and  Genre Data  \n",
    "\n",
    "Task3=driver.find_elements_by_xpath(\"//tbody/tr/td[2]\")\n",
    "for i in Task3:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        book_name.append(\"--\") \n",
    "    else:\n",
    "        book_name.append(i.text)\n",
    "        \n",
    "time.sleep(5)\n",
    "\n",
    "Task4=driver.find_elements_by_xpath(\"//tbody/tr/td[3]\")\n",
    "for i in Task4[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        author_name.append(\"--\") \n",
    "    else:\n",
    "        author_name.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task5=driver.find_elements_by_xpath(\"//tbody/tr/td[4]\")\n",
    "for i in Task5[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        volumes_sold.append(\"--\") \n",
    "    else:\n",
    "        volumes_sold.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task6=driver.find_elements_by_xpath(\"//tbody/tr/td[5]\")\n",
    "for i in Task6[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        publisher.append(\"--\") \n",
    "    else:\n",
    "        publisher.append(i.text)\n",
    "\n",
    "        \n",
    "Task7=driver.find_elements_by_xpath(\"//tbody/tr/td[6]\")\n",
    "for i in Task7[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        genre.append(\"--\") \n",
    "    else:\n",
    "        genre.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting  Final data.\n",
    "Highest_Selling_Novels = pd.DataFrame( {'Book Name' : book_name , 'Author Name' : author_name , 'Volumes Sold' : volumes_sold , 'Publisher' : publisher , 'Genre' : genre } )\n",
    "Highest_Selling_Novels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques -9 Scrape the details most watched tv series of all time from imdb.com.\n",
    "        Url = https://www.imdb.com/list/ls095964455/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "\n",
    "#Loading Driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\thunderbolt\\sof\\chromedriver.exe\")\n",
    "\n",
    "# Giving the name of website we have to  scrap\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "\n",
    "#Getting Url \n",
    "driver.get(url)\n",
    "\n",
    "name  = []\n",
    "year_span  = []\n",
    "genre  = []\n",
    "run_time  = []\n",
    "ratings = []\n",
    "votes  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting  Name , Year span   , genre  , runtime  , ratings and votes data. \n",
    "\n",
    "Task1=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "for i in Task1[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        name.append(\"--\") \n",
    "    else:\n",
    "        name.append(i.text)\n",
    "        \n",
    "time.sleep(5)\n",
    "\n",
    "Task2=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/span[2]\")\n",
    "for i in Task2[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        year_span.append(\"--\") \n",
    "    else:\n",
    "        year_span.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task3=driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[5]\")\n",
    "for i in Task3[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        genre.append(\"--\") \n",
    "    else:\n",
    "        genre.append(i.text)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "Task4=driver.find_elements_by_xpath(\"//p[@class='text-muted text-small']/span[3]\")\n",
    "for i in Task4[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        run_time.append(\"--\") \n",
    "    else:\n",
    "        run_time.append(i.text)\n",
    "\n",
    "        \n",
    "Task5=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-widget']/div/span[@class='ipl-rating-star__rating'][1]\")\n",
    "for i in Task5[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        ratings.append(\"--\") \n",
    "    else:\n",
    "        ratings.append(i.text)\n",
    "        \n",
    "        \n",
    "Task6=driver.find_elements_by_xpath(\"//div[@class='lister-item-content']/p[4]/span[2]\")\n",
    "for i in Task6[0:100]:\n",
    "    if i.text is NoSuchElementException  :\n",
    "        votes.append(\"--\") \n",
    "    else:\n",
    "        votes.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print (len(name),len(year_span),len(genre),len(run_time) , len(ratings) ,len(votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,735,876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>794,876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010– )</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>841,763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>252,039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>211,104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>42,872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>53,025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>157,258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015– )</td>\n",
       "      <td>Crime, Drama, Horror</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.2</td>\n",
       "      <td>33,632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>175,866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead     (2010– )   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series     (2015– )      Crime, Drama, Horror   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.3  1,735,876  \n",
       "1    51 min     8.8    794,876  \n",
       "2    44 min     8.2    841,763  \n",
       "3    60 min     7.6    252,039  \n",
       "4    43 min     7.6    211,104  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     42,872  \n",
       "96   50 min     7.8     53,025  \n",
       "97   42 min     8.1    157,258  \n",
       "98   45 min     7.2     33,632  \n",
       "99  572 min     8.6    175,866  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping final most watched tv series of all time data  from imbd.com.\n",
    "\n",
    "Imbd_Data = pd.DataFrame( {'Name' : name , 'Year Span' : year_span , 'Genre' : genre , 'Run Time' : run_time , 'Ratings': ratings  ,'Votes' : votes} )\n",
    "Imbd_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ques -10 Details of Datasets from UCI machine learning repositories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  selenium import webdriver\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import string\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "#Loading Driver\n",
    "driver =webdriver.Chrome(r\"C:\\Users\\thunderbolt\\sof\\chromedriver.exe\")\n",
    "\n",
    "# Giving the name of website we have to  scrap\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "\n",
    "#Getting Url \n",
    "driver.get(url)\n",
    "\n",
    "dataset_name = []\n",
    "data_type  = []\n",
    "task  = []\n",
    "attribute_type  = []\n",
    "no_of_instances  = []\n",
    "no_of_attribute  = []\n",
    "year = []\n",
    "\n",
    "time.sleep(10)\n",
    "Task1 = driver.find_element_by_xpath(\"//b/a[@href='datasets.php']\")\n",
    "Task1.click()\n",
    "\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the DataSet name , Data Type , Task , Attribute Type , No  of Instances , No  of Attribute and year Data.\n",
    "\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//p[@class='normal']/b/a\")]\n",
    "for url in urls[0:559]:\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//span[@class='heading']/b\").text\n",
    "        des=raw_description.replace(\"Data Set\",\"\")\n",
    "        dataset_name.append(des)\n",
    "    except NoSuchElementException :\n",
    "        dataset_name.append(\" \")\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//tbody/tr[1]/td[2]/p[@class='normal']\").text      \n",
    "        data_type.append(raw_description)\n",
    "    except NoSuchElementException :\n",
    "        data_type.append(\" \")\n",
    "\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//tbody/tr[3]/td[2]/p[@class='normal']\").text      \n",
    "        task.append(raw_description)\n",
    "    except NoSuchElementException :\n",
    "        task.append(\" \")\n",
    "\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//tbody/tr[2]/td[2]/p[@class='normal']\").text      \n",
    "        attribute_type.append(raw_description)\n",
    "    except NoSuchElementException :\n",
    "        attribute_type.append(\" \")\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//tbody/tr[1]/td[4]/p[@class='normal']\").text      \n",
    "        no_of_instances.append(raw_description)\n",
    "    except NoSuchElementException :\n",
    "        no_of_instances.append(\" \")\n",
    "\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//tbody/tr[2]/td[4]/p[@class='normal']\").text      \n",
    "        no_of_attribute.append(raw_description)\n",
    "    except NoSuchElementException :\n",
    "        no_of_attribute.append(\" \")\n",
    "\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//tbody/tr[2]/td[6]/p[@class='normal']\").text \n",
    "        des=raw_description[0:4]\n",
    "        year.append(des)\n",
    "    except NoSuchElementException :\n",
    "        year.append(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559 559 559 559 559 559 559\n"
     ]
    }
   ],
   "source": [
    "print (len(dataset_name),len(data_type),len(task),len(attribute_type) , len(no_of_instances) ,len(no_of_attribute) ,len(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>IIWA14-R820-Gazebo-Dataset-10Trajectories</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Integer</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>Guitar Chords finger positions</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2633</td>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>Russian Corpus of Biographical Texts</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>Codon usage</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>13028</td>\n",
       "      <td>69</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Intelligent Media Accelerometer and Gyroscope ...</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>800</td>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name     Data Type  \\\n",
       "0                                             Abalone   Multivariate   \n",
       "1                                               Adult   Multivariate   \n",
       "2                                           Annealing   Multivariate   \n",
       "3                        Anonymous Microsoft Web Data            N/A   \n",
       "4                                          Arrhythmia   Multivariate   \n",
       "..                                                 ...           ...   \n",
       "554         IIWA14-R820-Gazebo-Dataset-10Trajectories            N/A   \n",
       "555                    Guitar Chords finger positions           Text   \n",
       "556              Russian Corpus of Biographical Texts           Text   \n",
       "557                                       Codon usage   Multivariate   \n",
       "558  Intelligent Media Accelerometer and Gyroscope ...   Time-Series   \n",
       "\n",
       "                           Task              Attribute Type No of instances  \\\n",
       "0                Classification  Categorical, Integer, Real            4177   \n",
       "1                Classification        Categorical, Integer           48842   \n",
       "2                Classification  Categorical, Integer, Real             798   \n",
       "3           Recommender-Systems                 Categorical           37711   \n",
       "4                Classification  Categorical, Integer, Real             452   \n",
       "..                          ...                         ...             ...   \n",
       "554                  Regression                     Integer             N/A   \n",
       "555              Classification                         N/A            2633   \n",
       "556              Classification                         N/A             200   \n",
       "557  Classification, Clustering                         N/A           13028   \n",
       "558              Classification                        Real             800   \n",
       "\n",
       "    No of attribute  Year  \n",
       "0                 8  1995  \n",
       "1                14  1996  \n",
       "2                38   N/A  \n",
       "3               294  1998  \n",
       "4               279  1998  \n",
       "..              ...   ...  \n",
       "554             N/A  2020  \n",
       "555               5  2020  \n",
       "556               2  2020  \n",
       "557              69  2020  \n",
       "558               9  2020  \n",
       "\n",
       "[559 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting Final Data\n",
    "\n",
    "UCI=pd.DataFrame({\"Dataset Name\":dataset_name,\"Data Type\":data_type,\"Task\":task,\"Attribute Type\":attribute_type,\"No of instances\":no_of_instances,\n",
    "                \"No of attribute\":no_of_attribute , \"Year\" : year})\n",
    "UCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ************************************************************End of Document*************************************************** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
